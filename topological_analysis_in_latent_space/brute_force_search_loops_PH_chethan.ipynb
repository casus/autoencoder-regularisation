{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ramana44/topological-analysis-of-curved-spaces-and-hybridization-of-autoencoders')\n",
    "\n",
    "\n",
    "#from get_data import get_data, get_data_train, get_data_val\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "#import os\n",
    "#os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datasets import InMemDataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import nibabel as nib     # Read / write access to some common neuroimaging file formats\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "from scipy import interpolate\n",
    "import ot\n",
    "\n",
    "import jmp_solver1.surrogates\n",
    "import matplotlib\n",
    "matplotlib.rcdefaults() \n",
    "\n",
    "from models_un import AE_un\n",
    "from models import AE\n",
    "from activations import Sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Functions \n",
    "def _compute_distance_matrix(x, p=2):\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "\n",
    "    distances = torch.norm(x_flat[:, None] - x_flat, dim=2, p=p)\n",
    "\n",
    "    return distances\n",
    "\n",
    "# function to check whether the selected edge is going to close a potential loop\n",
    "\n",
    "def expecting_a_cycle(actual_new_test, my_edge):\n",
    "\n",
    "    left_ind = my_edge[0][0]\n",
    "    right_ind = my_edge[0][1]\n",
    "    found_right_ind = False\n",
    "    going_nowhere= False\n",
    "\n",
    "    new_test = actual_new_test\n",
    "\n",
    "    tracker = 0\n",
    "    no_branches_formed = True\n",
    "    while (not(found_right_ind) or not(going_nowhere)):\n",
    "\n",
    "        positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "\n",
    "        if(positions1.shape[0]>1):\n",
    "            edge_to_delete = new_test[positions1[0][0]]\n",
    "            no_branches_formed = False\n",
    "        \n",
    "        branches_rising = positions1.shape[0]\n",
    "\n",
    "        if(positions1.shape[0]==0):\n",
    "            going_nowhere= True\n",
    "            if(no_branches_formed):\n",
    "                break\n",
    "            \n",
    "            left_ind = my_edge[0][0]\n",
    "\n",
    "            deletable_edge_position1 = (actual_new_test == edge_to_delete[0]).nonzero(as_tuple=False)\n",
    "            deletable_edge_position2 = (actual_new_test == edge_to_delete[1]).nonzero(as_tuple=False)\n",
    "\n",
    "            deletable_edge_position1 = deletable_edge_position1[:,0]\n",
    "\n",
    "            deletable_edge_position2 = deletable_edge_position2[:,0]\n",
    "\n",
    "            a_cat_b1, counts1 = torch.cat([deletable_edge_position1, deletable_edge_position2]).unique(return_counts=True)\n",
    "            deletable_row_position = a_cat_b1[torch.where(counts1.gt(1))]\n",
    "\n",
    "            if(deletable_row_position.shape[0]==0):\n",
    "                going_nowhere = True\n",
    "                break\n",
    "\n",
    "            deletable_row_position = deletable_row_position[0]\n",
    "\n",
    "            actual_new_test = torch.cat((actual_new_test[:deletable_row_position], actual_new_test[deletable_row_position+1:]))\n",
    "            new_test = actual_new_test\n",
    "\n",
    "            positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "\n",
    "            if(tracker ==0):\n",
    "                break\n",
    "\n",
    "        if(positions1.shape[0]>1):\n",
    "            edge_to_delete = new_test[positions1[0][0]]\n",
    "            no_branches_formed = False\n",
    "                \n",
    "        first_position = positions1[0][0]\n",
    "        adj_edge1 = new_test[positions1[0][0]]\n",
    "        other_end1 = abs(positions1 - torch.tensor([[0, 1]]))\n",
    "\n",
    "\n",
    "        consec_pt1 = new_test[other_end1[0][0]][other_end1[0][1]]\n",
    "        consec_pt1 = int(consec_pt1)\n",
    "\n",
    "        if(consec_pt1 == right_ind):\n",
    "            found_right_ind = True\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            left_ind = consec_pt1\n",
    "            new_test = torch.cat((new_test[:first_position], new_test[first_position+1:]))\n",
    "            tracker = tracker+1\n",
    "    \n",
    "    return found_right_ind\n",
    "\n",
    "\n",
    "def get_all_edges(dist_matrix):\n",
    "    \n",
    "    dist_matrix = torch.unique(dist_matrix, dim=0)\n",
    "    dist_matrix = torch.unique(dist_matrix, dim=1)\n",
    "\n",
    "    upp_diag = torch.triu(dist_matrix, diagonal=1)\n",
    "\n",
    "    ff = upp_diag.sort()\n",
    "\n",
    "    sorted_upper_diag_edges = ff[0]\n",
    "\n",
    "    sorted_upper_diag_indices = ff[1]\n",
    "\n",
    "    flattened_uppdg_edges = torch.flatten(sorted_upper_diag_edges)\n",
    "\n",
    "    non_zero_flattened_uppdg_edges = flattened_uppdg_edges[flattened_uppdg_edges.nonzero()]\n",
    "\n",
    "    non_zero_flattened_uppdg_edges = non_zero_flattened_uppdg_edges.reshape(non_zero_flattened_uppdg_edges.shape[0])\n",
    "\n",
    "    increasing_edges = non_zero_flattened_uppdg_edges.sort()[0]\n",
    "    increasing_edges = torch.unique(increasing_edges, dim=0)\n",
    "    \n",
    "    #print('increasing_edges', increasing_edges)\n",
    "    \n",
    "    selected_edges = torch.tensor([])\n",
    "    dead_indices = torch.tensor([])\n",
    "    potential_triangles = torch.tensor([])\n",
    "    edge_leads_to_loop = False\n",
    "\n",
    "    for i in range(increasing_edges.shape[0]):\n",
    "        a = (upp_diag == increasing_edges[i]).nonzero(as_tuple=False)\n",
    "\n",
    "        if(selected_edges.shape[0] > 1):\n",
    "            edge_leads_to_loop = False #expecting_a_cycle(selected_edges, a)\n",
    "\n",
    "        if(not(edge_leads_to_loop)):\n",
    "            selected_edges = torch.cat(((selected_edges, a)), 0)\n",
    "\n",
    "    #print('selected_edges', selected_edges)\n",
    "    zeroD_PH = torch.tensor([])\n",
    "    for i in range(selected_edges.shape[0]):    \n",
    "        death = dist_matrix[int(selected_edges[i][0])][int(selected_edges[i][1])]\n",
    "        death = death.reshape(1,1)    \n",
    "        zeroD_PH = torch.cat(((zeroD_PH, death)), 0)\n",
    "\n",
    "    births = torch.zeros(zeroD_PH.shape[0], 1)\n",
    "    zeroD_PH_births_deaths = torch.cat((births, zeroD_PH ),1)\n",
    "\n",
    "    return selected_edges, zeroD_PH_births_deaths\n",
    "\n",
    "    \n",
    "def indices_array_any_size(m, n):\n",
    "    r = np.arange(n)\n",
    "    s = np.arange(m)\n",
    "    out = np.empty((n,m,2),dtype=int)\n",
    "    out[:,:,0] = r[:,None]\n",
    "    out[:,:,1] = s\n",
    "    output = out.reshape(m*n,2)\n",
    "    output = torch.tensor(output).type(torch.FloatTensor)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "#Computationally efficient than  previous method to calculate M \n",
    "def compute_M(img_indices, p=2):\n",
    "    x = img_indices\n",
    "    x_flat = x.view(x.size(0), -1)\n",
    "    distances = torch.norm(x_flat[:, None] - x_flat, dim=2, p=p)\n",
    "    \n",
    "    return distances**2\n",
    "\n",
    "\n",
    "def wass_distance(image1,image2, M_matrix, reg):\n",
    "    gs = ((image1 + 10**(-6)).reshape(M_matrix.shape[0],1)) / torch.sum((image1))\n",
    "    h = ((image2 + 10**(-6)).reshape(M_matrix.shape[0],1)) / torch.sum((image2))\n",
    "    # 10**(-10) added to avoid numerical errors in sinkhorn\n",
    "    wassDistance = ot.sinkhorn2(h, gs, M_matrix, reg)\n",
    "    #0.04 is the regularization parameter. You can play around with it \n",
    "    return wassDistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained rAE and bAE\n",
    "latent_dims = [20, 18, 16, 14, 12, 10, 8, 6, 4, 2]\n",
    "all_hyb_base_models = []\n",
    "\n",
    "Analys_size = 20\n",
    "\n",
    "all_test_coeffs = []\n",
    "all_X_p = []\n",
    "for lat_dim in latent_dims:\n",
    "    deg_quad = 20\n",
    "    u_ob = jmp_solver1.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,32)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    testImages = torch.load('/home/ramana44/topological-analysis-of-curved-spaces-and-hybridization-of-autoencoders-STORAGE_SPACE/FMNIST_RK_coeffs/testImages.pt',map_location=torch.device('cpu'))\n",
    "    testCoeffs = torch.load('/home/ramana44/topological-analysis-of-curved-spaces-and-hybridization-of-autoencoders-STORAGE_SPACE/FMNIST_RK_coeffs/coeffs_saved/LSTSQ_testcoeffs_FMNIST_dq'+str(deg_quad)+'.pt',map_location=torch.device('cpu'))\n",
    "\n",
    "    testImages = testImages[:Analys_size]\n",
    "    testCoeffs = testCoeffs[:Analys_size]\n",
    "\n",
    "    path_hyb = '/home/ramana44/topological-analysis-of-curved-spaces-and-hybridization-of-autoencoders-STORAGE_SPACE/FMNIST_RK_space/output/MRT_full/test_run_saving/'\n",
    "    path_unhyb = '/home/ramana44/FashionMNIST5LayersTrials/output/MRT_full/test_run_saving/'\n",
    "\n",
    "    #specify hyperparameters\n",
    "    reg_nodes_sampling = 'legendre'\n",
    "    alpha = 0.5\n",
    "    frac = 0.4\n",
    "    hidden_size = 100\n",
    "    deg_poly = 21\n",
    "    deg_poly_forRK = 21\n",
    "    latent_dim = lat_dim\n",
    "    lr = 0.0001\n",
    "    no_layers = 3\n",
    "    no_epochs= 100\n",
    "    name_hyb = '_'+reg_nodes_sampling+'_'+str(frac)+'_'+str(alpha)+'_'+str(hidden_size)+'_'+str(deg_poly_forRK)+'_'+str(latent_dim)+'_'+str(lr)+'_'+str(no_layers)#+'_'+str(no_epochs)\n",
    "    name_unhyb = '_'+reg_nodes_sampling+'__'+str(frac)+'_'+str(alpha)+'_'+str(hidden_size)+'_'+str(deg_poly)+'_'+str(latent_dim)+'_'+str(lr)+'_'+str(no_layers)#+'_'+str(no_epochs)\n",
    "\n",
    "    inp_dim_hyb = (deg_quad+1)*(deg_quad+1)\n",
    "\n",
    "    inp_dim_unhyb = [1,32,32]\n",
    "\n",
    "    RK_model_reg = AE(inp_dim_hyb, hidden_size, latent_dim, no_layers, Sin()).to(device)\n",
    "    #RK_model_base = AE(inp_dim_hyb, hidden_size, latent_dim, no_layers, Sin()).to(device)\n",
    "\n",
    "    RK_model_reg.load_state_dict(torch.load(path_hyb+'model_regLSTQS'+str(deg_quad)+''+name_hyb, map_location=torch.device('cpu')))\n",
    "    #RK_model_base.load_state_dict(torch.load(path_hyb+'model_baseLSTQS'+str(deg_quad)+''+name_hyb, map_location=torch.device('cpu')))\n",
    "\n",
    "    all_hyb_base_models.append(RK_model_reg)\n",
    "    all_test_coeffs.append(testCoeffs)\n",
    "    all_X_p.append(X_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testImages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8939/2225488608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestImages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'testImages' is not defined"
     ]
    }
   ],
   "source": [
    "testImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46456/557051121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_rec_bAE_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrec_bAE_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hyb_base_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_coeffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.view(all_test_coeffs[i].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrec_bAE_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_bAE_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_rec_bAE_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_bAE_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latent_dims' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "all_rec_bAE_test = []\n",
    "for i in range(len(latent_dims)):\n",
    "    rec_bAE_test = all_hyb_base_models[i].encoder(all_test_coeffs[i].float())#.view(all_test_coeffs[i].shape)\n",
    "    rec_bAE_test = torch.tensor(rec_bAE_test, requires_grad=False)\n",
    "    all_rec_bAE_test.append(rec_bAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_pt_cld = all_rec_bAE_test[0]\n",
    "\n",
    "latent_pt_cld = latent_pt_cld[:40]\n",
    "\n",
    "latent_pt_cld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix_lat1024 = _compute_distance_matrix(testImages, p=2)\n",
    "edges_lat1024, edge_lengths_lat1024 = get_all_edges(dist_matrix_lat1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([190, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_lat1024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Kernel myenv (Python 3.9.7) is not usable. Check the Jupyter output tab for more information. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dist_matrix_lat20 = _compute_distance_matrix(all_rec_bAE_test[0], p=2)\n",
    "edges_lat20, edge_lengths_lat20 = get_all_edges(dist_matrix_lat20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([190, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_lat20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unbranched edges from the other side till there is branch\n",
    "\n",
    "def right_side_pts_before_branching(actual_new_test, my_edge):\n",
    "\n",
    "    left_ind = my_edge[0][1]\n",
    "    right_ind = my_edge[0][0]\n",
    "    found_right_ind = False\n",
    "    going_nowhere= False\n",
    "\n",
    "    new_test = actual_new_test\n",
    "    actual_new_test_an = actual_new_test\n",
    "    \n",
    "    tracker = 0\n",
    "    no_branches_formed = True\n",
    "    loop_tracker = 0\n",
    "    positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "    loops_collec = []\n",
    "    current_loop = torch.tensor([])\n",
    "    consec_pt_tracker = torch.tensor([])\n",
    "    while (not(found_right_ind) or not(going_nowhere)):\n",
    "\n",
    "        positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "        \n",
    "        if(positions1.shape[0]>1):\n",
    "            break\n",
    "\n",
    "        branches_rising = positions1.shape[0]\n",
    "\n",
    "        if(positions1.shape[0]==0):\n",
    "            #lets see\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            first_position = positions1[0][0]\n",
    "\n",
    "            adj_edge1 = new_test[positions1[0][0]]\n",
    "            other_end1 = abs(positions1 - torch.tensor([[0, 1]]))\n",
    "\n",
    "\n",
    "            consec_pt1 = new_test[other_end1[0][0]][other_end1[0][1]]\n",
    "            consec_pt1s = torch.unsqueeze(consec_pt1,0)\n",
    "            consec_pt_tracker = torch.cat((consec_pt_tracker, consec_pt1s),0)\n",
    "            consec_pt1 = int(consec_pt1)\n",
    "\n",
    "            current_loop = torch.cat((current_loop,adj_edge1),0)\n",
    "            current_loop1 = current_loop.reshape(int(current_loop.shape[0]/2),2)\n",
    "            \n",
    "            if(consec_pt1 == my_edge[0][0]):\n",
    "                current_loop = torch.tensor([])\n",
    "                \n",
    "            if(consec_pt1 == right_ind):\n",
    "                my_edge1 = torch.squeeze(my_edge,0)\n",
    "                current_loop = torch.cat((current_loop,my_edge1),0)\n",
    "                current_loop1 = current_loop.reshape(int(current_loop.shape[0]/2),2)                \n",
    "\n",
    "                loops_collec.append(current_loop1)\n",
    "\n",
    "                loop_tracker = loop_tracker + 1\n",
    "            left_ind = consec_pt1\n",
    "            new_test = torch.cat((new_test[:first_position], new_test[first_position+1:]))\n",
    "            tracker = tracker+1\n",
    "    \n",
    "    return consec_pt_tracker\n",
    "\n",
    "# function to check whether the selected edge is going to close a potential loop\n",
    "\n",
    "def get_all_loops_formed(actual_new_test, my_edge):\n",
    "\n",
    "    other_side_unbranched_pts = right_side_pts_before_branching(actual_new_test, my_edge)\n",
    "    #print('other_side_unbranched_pts.shape',other_side_unbranched_pts.shape[0])\n",
    "    left_ind = my_edge[0][0]\n",
    "    right_ind = my_edge[0][1]\n",
    "    found_right_ind = False\n",
    "    going_nowhere= False\n",
    "\n",
    "    new_test = actual_new_test\n",
    "    actual_new_test_an = actual_new_test\n",
    "    \n",
    "    tracker = 0\n",
    "    no_branches_formed = True\n",
    "    loop_tracker = 0\n",
    "    positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "    loops_collec = []\n",
    "    current_loop = torch.tensor([])\n",
    "    consec_pt_tracker = torch.tensor([])\n",
    "    while (not(found_right_ind) or not(going_nowhere)):\n",
    "\n",
    "        positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "        #print(new_test)\n",
    "        #print()\n",
    "        #print('positions1.shape[0]',positions1.shape[0])\n",
    "        #print()\n",
    "        \n",
    "        if(positions1.shape[0]>1):\n",
    "            #edg_q_del = new_test[positions1[0][0]]\n",
    "            other_end_con = abs(positions1 - torch.tensor([[0, 1]]))\n",
    "            consec_pt_con = new_test[other_end_con[0][0]][other_end_con[0][1]]\n",
    "            #print('did i get consec_pt_con ', consec_pt_con)\n",
    "            #print('now check if it works', not(consec_pt_con in consec_pt_tracker))\n",
    "            \n",
    "            if(not(other_side_unbranched_pts.shape[0] == 0)):\n",
    "                if(not(consec_pt_con in consec_pt_tracker) and not(consec_pt_con==other_side_unbranched_pts[-2])):\n",
    "                    edge_to_delete = new_test[positions1[0][0]]\n",
    "            else:\n",
    "                if(not(consec_pt_con in consec_pt_tracker)):\n",
    "                    edge_to_delete = new_test[positions1[0][0]]                \n",
    "            no_branches_formed = False\n",
    "            #print('edge_to_delete first',edge_to_delete)\n",
    "        branches_rising = positions1.shape[0]\n",
    "\n",
    "        if(positions1.shape[0]==0):\n",
    "            current_loop = torch.tensor([])\n",
    "            consec_pt_tracker = torch.tensor([])\n",
    "            #going_nowhere= True\n",
    "            '''if(no_branches_formed):\n",
    "                break'''\n",
    "            \n",
    "            left_ind = my_edge[0][0]\n",
    "\n",
    "            deletable_edge_position1 = (actual_new_test == edge_to_delete[0]).nonzero(as_tuple=False)\n",
    "            deletable_edge_position2 = (actual_new_test == edge_to_delete[1]).nonzero(as_tuple=False)\n",
    "\n",
    "            deletable_edge_position1 = deletable_edge_position1[:,0]\n",
    "\n",
    "            deletable_edge_position2 = deletable_edge_position2[:,0]\n",
    "\n",
    "            a_cat_b1, counts1 = torch.cat([deletable_edge_position1, deletable_edge_position2]).unique(return_counts=True)\n",
    "            deletable_row_position = a_cat_b1[torch.where(counts1.gt(1))]\n",
    "            #print()\n",
    "            #print('deletable_row_position',deletable_row_position)\n",
    "            \n",
    "            if(deletable_row_position.shape[0]==0):\n",
    "                #going_nowhere = True\n",
    "                current_loop = torch.tensor([])\n",
    "                break\n",
    "\n",
    "            deletable_row_position = deletable_row_position[0]\n",
    "            \n",
    "            #print('Does my edge to delete contain my edge left index ? ', my_edge[0][0] in edge_to_delete)\n",
    "            #print()\n",
    "            actual_new_test = torch.cat((actual_new_test[:deletable_row_position], actual_new_test[deletable_row_position+1:]))\n",
    "            if(my_edge[0][0] in edge_to_delete):\n",
    "\n",
    "                deletable_edge_position1 = (actual_new_test_an == edge_to_delete[0]).nonzero(as_tuple=False)\n",
    "                deletable_edge_position2 = (actual_new_test_an == edge_to_delete[1]).nonzero(as_tuple=False)\n",
    "\n",
    "                deletable_edge_position1 = deletable_edge_position1[:,0]\n",
    "\n",
    "                deletable_edge_position2 = deletable_edge_position2[:,0]\n",
    "\n",
    "                a_cat_b1, counts1 = torch.cat([deletable_edge_position1, deletable_edge_position2]).unique(return_counts=True)\n",
    "                deletable_row_position = a_cat_b1[torch.where(counts1.gt(1))]\n",
    "                #print()\n",
    "                #print('deletable_row_position',deletable_row_position)\n",
    "\n",
    "                if(deletable_row_position.shape[0]==0):\n",
    "                    #going_nowhere = True\n",
    "                    current_loop = torch.tensor([])\n",
    "                    break\n",
    "\n",
    "                deletable_row_position = deletable_row_position[0]\n",
    "                \n",
    "                actual_new_test_an = torch.cat((actual_new_test_an[:deletable_row_position], actual_new_test_an[deletable_row_position+1:]))    \n",
    "                actual_new_test = actual_new_test_an\n",
    "                \n",
    "            #actual_new_test = torch.cat((actual_new_test[:deletable_row_position], actual_new_test[deletable_row_position+1:]))\n",
    "            #print('what is this', actual_new_test)\n",
    "            new_test = actual_new_test\n",
    "\n",
    "            positions1 = (new_test == left_ind).nonzero(as_tuple=False)\n",
    "            #print('whats happening here',positions1.shape )\n",
    "            #print('is the same edge still to delete', edge_to_delete)\n",
    "            if(tracker ==0):\n",
    "                break\n",
    "\n",
    "            '''if(positions1.shape[0]>1):\n",
    "            edge_to_delete = new_test[positions1[0][0]]\n",
    "            no_branches_formed = False'''\n",
    "        else:\n",
    "            first_position = positions1[0][0]\n",
    "            #print('first_position',first_position)\n",
    "            adj_edge1 = new_test[positions1[0][0]]\n",
    "            other_end1 = abs(positions1 - torch.tensor([[0, 1]]))\n",
    "\n",
    "\n",
    "            consec_pt1 = new_test[other_end1[0][0]][other_end1[0][1]]\n",
    "            consec_pt1s = torch.unsqueeze(consec_pt1,0)\n",
    "            consec_pt_tracker = torch.cat((consec_pt_tracker, consec_pt1s),0)\n",
    "            consec_pt1 = int(consec_pt1)\n",
    "\n",
    "                \n",
    "            #print('consec_pt1',consec_pt1)\n",
    "            #print('adj_edge1',adj_edge1)\n",
    "            current_loop = torch.cat((current_loop,adj_edge1),0)\n",
    "            current_loop1 = current_loop.reshape(int(current_loop.shape[0]/2),2)\n",
    "            #print('consec_pt_tracker',consec_pt_tracker)\n",
    "            \n",
    "            if(consec_pt1 == my_edge[0][0]):\n",
    "                current_loop = torch.tensor([])\n",
    "                \n",
    "            if(consec_pt1 == right_ind):\n",
    "                my_edge1 = torch.squeeze(my_edge,0)\n",
    "                current_loop = torch.cat((current_loop,my_edge1),0)\n",
    "                current_loop1 = current_loop.reshape(int(current_loop.shape[0]/2),2)                \n",
    "                #found_right_ind = True\n",
    "                #print('current_loop',current_loop1)\n",
    "                #current_loop1 = torch.unsqueeze(current_loop1,0)\n",
    "                #print('current_loop shape now',current_loop1.shape)\n",
    "                #print('loop_tracker', loop_tracker)\n",
    "                loops_collec.append(current_loop1)\n",
    "                #loops_collec[loop_tracker] = current_loop1\n",
    "                loop_tracker = loop_tracker + 1\n",
    "                #print()\n",
    "                #print(\"Wow! Found a loop here\")\n",
    "                #print()\n",
    "                #break\n",
    "\n",
    "            #else:\n",
    "\n",
    "            left_ind = consec_pt1\n",
    "            new_test = torch.cat((new_test[:first_position], new_test[first_position+1:]))\n",
    "            #print('new_test',new_test)\n",
    "            tracker = tracker+1\n",
    "    \n",
    "    #loops_collec = torch.FloatTensor(loops_collec)\n",
    "    return loops_collec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges_lat20' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33618/214041393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_lat20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0medge_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges_lat20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_collection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edges_lat20' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(edges_lat20.shape[0]):\n",
    "\n",
    "    edge_collection = edges_lat20[:i+3]\n",
    "\n",
    "    target_edges = edge_collection[:-1]\n",
    "\n",
    "    input_edges = edge_collection[-1]\n",
    "\n",
    "    #last_edge = edges_lat20[i+3]\n",
    "\n",
    "    loops = expecting_a_cycle(target_edges, input_edges)\n",
    "\n",
    "    print(loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the function\n",
    "current_edge_collec = torch.tensor([[10., 11.],\n",
    "        [4., 15.],\n",
    "        [14., 15.],\n",
    "        [11., 12.],\n",
    "        [2., 3.],\n",
    "        [ 5., 14.],\n",
    "        [11., 9.],\n",
    "        [ 12., 13.],\n",
    "        [7., 8.],\n",
    "        [ 3., 4.],\n",
    "        [9., 2.],\n",
    "        [13., 5.],\n",
    "        [8., 4.],\n",
    "        [ 1.,  2.],\n",
    "        [1., 5.]])\n",
    "#my_edge = torch.tensor([[ 9, 18]])\n",
    "\n",
    "curr_edge = torch.tensor([[ 5, 7]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5., 14.],\n",
       "         [14., 15.],\n",
       "         [ 4., 15.],\n",
       "         [ 8.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [ 5.,  7.]]),\n",
       " tensor([[13.,  5.],\n",
       "         [12., 13.],\n",
       "         [11., 12.],\n",
       "         [11.,  9.],\n",
       "         [ 9.,  2.],\n",
       "         [ 2.,  3.],\n",
       "         [ 3.,  4.],\n",
       "         [ 8.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [ 5.,  7.]]),\n",
       " tensor([[1., 5.],\n",
       "         [1., 2.],\n",
       "         [2., 3.],\n",
       "         [3., 4.],\n",
       "         [8., 4.],\n",
       "         [7., 8.],\n",
       "         [5., 7.]])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expecting_a_cycle(current_edge_collec, curr_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ee815085acdfe8ec7427c3e245a848b8e2a21c8f3a89c6ee352c1052f53cf80"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
