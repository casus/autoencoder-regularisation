{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_paths) 2451\n"
     ]
    }
   ],
   "source": [
    "from get_data import get_data\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from datasets import InMemDataLoader\n",
    "\n",
    "\n",
    "#### create list of all nifti file paths ###\n",
    "#d ='/bigdata/hplsim/aipp/RLtract/deepFibreTracking/examples/data/HCP_extended/'\n",
    "'''d = '/bigdata/hplsim/aipp/RLtract/deepFibreTracking/examples/data/HCP_extended/'\n",
    "all_paths = [os.path.join(d, o) for o in os.listdir(d) \n",
    "                    if os.path.isdir(os.path.join(d,o))]\n",
    "all_paths = [p + '/T1w/T1w_acpc_dc_restore_1.25.nii.gz' for p in all_paths]'''\n",
    "\n",
    "'''d = '/home/ramana44/all_scans_single_channel_equal_dim/'\n",
    "all_paths = [os.path.join(d, o) for o in os.listdir(d) \n",
    "                    if os.path.isdir(os.path.join(d,o))]\n",
    "all_paths = [p for p in all_paths]'''\n",
    "all_paths = []\n",
    "for root, dirs, files in os.walk(os.path.abspath(\"/home/ramana44/all_scans_single_channel_equal_dim/\")):\n",
    "    for file in files:\n",
    "        #print(os.path.join(root, file))\n",
    "        all_paths.append((os.path.join(root, file)))\n",
    "\n",
    "print('len(all_paths)',len(all_paths))\n",
    "\n",
    "\n",
    "### load data ###\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def get_train_test_set(paths, device, batch_size=200, train_set_size=0.8, test_set_size=0.2):\n",
    "    assert train_set_size + test_set_size <= 1., \"Train and test set size should not exceed 100%\"\n",
    "    \n",
    "    path_indices = np.arange(len(paths))\n",
    "    #np.random.shuffle(path_indices)                             # randomize indices of the paths for train and test set selection\n",
    "    \n",
    "    num_train = int(np.round_(len(paths) * train_set_size))     # calc amount of training sets to load\n",
    "    num_test = int(np.round_(len(paths) * test_set_size))       # calc amount of test sets to load\n",
    "    train_indices = path_indices[:num_train]                    # select unique and random indices from all paths\n",
    "    test_indices = path_indices[-num_test:]                     # for train and test set\n",
    "\n",
    "\n",
    "    train_data = get_data([paths[i] for i in train_indices], device)  # only load specific indices preveiously selected\n",
    "    test_data = get_data([paths[i] for i in test_indices], device)\n",
    "    print('train_data.shape',train_data.shape)\n",
    "\n",
    "    train_loader = InMemDataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True) # init dataloader for train and test set\n",
    "    test_loader = InMemDataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True) \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "reg_nodes_sampling = \"legendre\"\n",
    "alpha = 0.5\n",
    "hidden_size = 1000\n",
    "deg_poly = 20\n",
    "latent_dim = 80\n",
    "lr = 1e-4\n",
    "no_layers = 5\n",
    "train_set_size = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before normalize 1961\n",
      "after normalize 1961\n",
      "initial torch.Size([1961, 96, 96, 60])\n",
      "after permute torch.Size([1961, 60, 96, 96])\n",
      "after 123 torch.Size([1961, 25, 96, 96])\n",
      "after reshape torch.Size([49025, 96, 96])\n",
      "after unsqueeze torch.Size([49025, 1, 96, 96])\n",
      "before normalize 490\n",
      "after normalize 490\n",
      "initial torch.Size([490, 96, 96, 60])\n",
      "after permute torch.Size([490, 60, 96, 96])\n",
      "after 123 torch.Size([490, 25, 96, 96])\n",
      "after reshape torch.Size([12250, 96, 96])\n",
      "after unsqueeze torch.Size([12250, 1, 96, 96])\n",
      "train_data.shape torch.Size([49025, 1, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_train_test_set(all_paths, device, train_set_size=train_set_size, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ee815085acdfe8ec7427c3e245a848b8e2a21c8f3a89c6ee352c1052f53cf80"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
