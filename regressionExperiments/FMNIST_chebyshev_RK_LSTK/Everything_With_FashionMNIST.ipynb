{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import minterpy as mp\n",
    "from minterpy.extras.regression import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFashionMNIST(batch_size = 10):\n",
    "    fashionmnist_data = torchvision.datasets.FashionMNIST(download=True, root = 'data/fashionmnist', transform = \n",
    "                                                                                 transforms.Compose([transforms.Resize(32),\n",
    "                                                                                 transforms.ToTensor(), \n",
    "                                                                                 transforms.Lambda(lambda x: x.repeat(1, 1, 1))\n",
    "                                                                                 ]))\n",
    "\n",
    "    fashionmnist_data_test = torchvision.datasets.FashionMNIST(download=True, root = 'data/fashionmnist', train=False, transform = \n",
    "                                                                                 transforms.Compose([transforms.Resize(32),\n",
    "                                                                                 transforms.ToTensor(), \n",
    "                                                                                 transforms.Lambda(lambda x: x.repeat(1, 1, 1))\n",
    "                                                                                 ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(fashionmnist_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=16)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(fashionmnist_data_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=16)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "def getDataset(dataset = \"MNIST\", batch_size = 10):\n",
    "    if(dataset == \"MNIST\"):\n",
    "        train_loader, test_loader = getMNIST(batch_size)\n",
    "        noChannels,dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "    elif(dataset == \"FashionMNIST\"):\n",
    "        train_loader, test_loader = getFashionMNIST(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "    elif(dataset == \"Cifar10\"):\n",
    "        train_loader, test_loader = getCifar10(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "        \"\"\"\n",
    "    elif(dataset == \"cityscapes\"):\n",
    "        train_loader, test_loader = getcityscapes(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return None, None, None, None, None    \n",
    "        \n",
    "    return train_loader, test_loader, noChannels, dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, noChannels, dx, dy = getDataset(\"FashionMNIST\", 60000)  # FashionMNIST , MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inum, (batch_x, label) in enumerate(train_loader):\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = batch_x[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "import scipy.integrate\n",
    "#sys.path.insert(1, '/home/suarez08/PhD_PINNs/PIPS_framework')\n",
    "from jmp_solver.sobolev import Sobolev\n",
    "from jmp_solver.sobolev import Sobolev\n",
    "from jmp_solver.solver import Solver\n",
    "from jmp_solver.utils import matmul\n",
    "import jmp_solver.surrogates\n",
    "import time\n",
    "#sys.path.insert(1, '/home/suarez08/minterpy/src')\n",
    "import minterpy as mp\n",
    "from jmp_solver.diffeomorphisms import hyper_rect\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#style.use('dark_background')\n",
    "matplotlib.rcdefaults() \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14592/425691577.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Fr = torch.tensor(listedImage).reshape(32*32)\n",
      "/tmp/ipykernel_14592/425691577.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_14592/425691577.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_14592/425691577.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "deg_Quads = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 25, 27]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    diffeo_param = hyper_rect(*rect)\n",
    "    sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    sob_param.set_s(0)\n",
    "    #####\n",
    "    x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    metric_param = sob_param.metric()\n",
    "    W_param = sob_param.get_leja_weights()\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    metric_2d = sob_param.metric(weak=True)\n",
    "    x_l = sob_param.get_xs()\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,32)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "        #print('listedImage.shape',listedImage.shape)\n",
    "        Fr = torch.tensor(listedImage).reshape(32*32)\n",
    "\n",
    "        def grad_x(t,theta):\n",
    "            theta_t = torch.tensor(theta)\n",
    "            return -2*torch.matmul(X_p.T,(torch.matmul(X_p,theta_t)-Fr)).detach().numpy()\n",
    "\n",
    "        def give_theta_t():\n",
    "            start = time.time()\n",
    "            u_ob.set_weights_val(0.0)\n",
    "            theta_0 =  list(u_ob.parameters())[0][0]\n",
    "            dt = 0.01\n",
    "            theta_t = theta_0\n",
    "            for k in range(20):\n",
    "                theta_int =  scipy.integrate.RK45(grad_x, 0.1, theta_t.detach().numpy(), 100)\n",
    "                theta_int.step()\n",
    "                theta_t = torch.tensor(theta_int.y)\n",
    "            return theta_t\n",
    "\n",
    "        act_theta = give_theta_t()\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(32,32)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.87196829704065,\n",
       " 14.705521425489728,\n",
       " 15.59054487767575,\n",
       " 15.656339253492204,\n",
       " 15.684665797906586,\n",
       " 16.250317982980956,\n",
       " 17.958171387840075,\n",
       " 18.146200488820664,\n",
       " 18.316598748916448,\n",
       " 18.825832477093623,\n",
       " 19.849749231759542,\n",
       " 20.02019152384107,\n",
       " 21.100318263484038,\n",
       " 21.805093165238016,\n",
       " 22.559551383925193,\n",
       " 22.739788598837592]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for Analytical\n",
    "\n",
    "\n",
    "\n",
    "orig = batch_x[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14592/2590548646.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Fr = torch.tensor(listedImage).reshape(32*32).double()\n",
      "/tmp/ipykernel_14592/2590548646.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_14592/2590548646.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_14592/2590548646.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "deg_Quads = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 25, 27]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    #rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    #sob_param.set_s(0)\n",
    "    #####\n",
    "    #x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    #metric_param = sob_param.metric()\n",
    "    #W_param = sob_param.get_leja_weights()\n",
    "    #u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    #metric_2d = sob_param.metric(weak=True)\n",
    "    #x_l = sob_param.get_xs()\n",
    "    #X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,32)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "        Fr = torch.tensor(listedImage).reshape(32*32).double()\n",
    "        KsK = matmul(X_p.T, X_p)\n",
    "        Ksf = matmul(X_p.T, Fr)\n",
    "        w = matmul(KsK.inverse(), Ksf)\n",
    "\n",
    "        act_theta = w\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(32,32)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.904946334380895,\n",
       " 14.559870096769513,\n",
       " 14.47573308185149,\n",
       " 11.741741165919608,\n",
       " 10.616678625238961,\n",
       " 9.558669160388032,\n",
       " 9.454745750698061,\n",
       " 7.9833733720274385,\n",
       " 7.787395170581462,\n",
       " 7.38904400953063,\n",
       " 7.075864489110396,\n",
       " 6.899823008681693,\n",
       " 6.01650782587416,\n",
       " 4.775130267424884,\n",
       " 4.738787751441561,\n",
       " 4.72966069613055]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_noise4p3_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.86906669042045,\n",
       " 14.69990715460941,\n",
       " 15.583248371670644,\n",
       " 15.6447811023814,\n",
       " 15.682281076217128,\n",
       " 16.248536876654217,\n",
       " 17.97620289538086,\n",
       " 18.088759110066533,\n",
       " 18.219046905847073,\n",
       " 18.780315743160962,\n",
       " 19.941102765161954,\n",
       " 20.12937080479736,\n",
       " 21.48790801598562,\n",
       " 21.93849462123008,\n",
       " 23.672872202723923,\n",
       " 28.440621302564498]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14592/2339891751.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  get = np.linalg.lstsq(np.array(X_p), listedImage.reshape(32*32), rcond='warn')\n",
      "/tmp/ipykernel_14592/2339891751.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_14592/2339891751.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_14592/2339891751.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "# Next is LSTQS\n",
    "\n",
    "deg_Quads = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 25, 27]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    #rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    #sob_param.set_s(0)\n",
    "    #####\n",
    "    #x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    #metric_param = sob_param.metric()\n",
    "    #W_param = sob_param.get_leja_weights()\n",
    "    #u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    #metric_2d = sob_param.metric(weak=True)\n",
    "    #x_l = sob_param.get_xs()\n",
    "    #X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,32)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "\n",
    "        get = np.linalg.lstsq(np.array(X_p), listedImage.reshape(32*32), rcond='warn')\n",
    "        act_theta = torch.tensor(get[0])\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(32,32)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_len = orig.shape[0]\n",
    "im_len\n",
    "def getLejaOrderedImage(im2d, Q_exact):\n",
    "    Q_exact_sorted = (Q_exact)\n",
    "    leg_pts_image_sorted = torch.tensor([])\n",
    "    for i in Q_exact_sorted:\n",
    "        for j in Q_exact_sorted:\n",
    "            i_int = i.astype(int)\n",
    "            j_int = j.astype(int)\n",
    "            if(i_int == 0 or i_int == (im_len-1) or j_int == 0 or j_int == (im_len-1) ):\n",
    "                req_value = im2d[i_int][j_int]\n",
    "            else:\n",
    "                x_co_1 = i_int\n",
    "                x_co_2 = i_int+1\n",
    "                y_co_1 =j_int\n",
    "                y_co_2 = j_int+1\n",
    "\n",
    "                Q_ev_11 = im2d[x_co_1][y_co_1]\n",
    "                Q_ev_12 = im2d[x_co_1][y_co_2]\n",
    "                Q_ev_21 = im2d[x_co_2][y_co_1]\n",
    "                Q_ev_22 = im2d[x_co_2][y_co_2]\n",
    "\n",
    "                x_co = i\n",
    "                y_co = j\n",
    "\n",
    "                term_1 = ( ( ( (x_co_2 - x_co) * (y_co_2 - y_co) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_11)\n",
    "                term_2 = (( ( (x_co - x_co_1) * (y_co_2 - y_co) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_21)\n",
    "                term_3 = ( ( ( (x_co_2 - x_co) * (y_co - y_co_1) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_12)\n",
    "                term_4 = ( ( ( (x_co - x_co_1) * (y_co - y_co_1) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_22)\n",
    "\n",
    "                req_value = term_1 + term_2 + term_3 + term_4                \n",
    "            Fr1 = torch.tensor([req_value])\n",
    "            leg_pts_image_sorted = torch.cat((leg_pts_image_sorted, Fr1)) \n",
    "    return leg_pts_image_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the analytic gradient flow, the trained model is u_ob\n",
    "\n",
    "def getImageFromCoefficients(imageBilinearEncoded,X_p ):\n",
    "    Fr = imageBilinearEncoded\n",
    "    Fr = torch.tensor(Fr)\n",
    "    start = time.time()\n",
    "    K = torch.eye(len(X_p))\n",
    "    KsK = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),X_p)))\n",
    "    Ksf = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),Fr)))\n",
    "    w = matmul(KsK.inverse(), Ksf)\n",
    "    u_ob.set_weights(w)\n",
    "    end = time.time()\n",
    "    #print('time consumption: %.2fs' % (end-start))\n",
    "\n",
    "    Ksf = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),Fr)))\n",
    "    w = matmul(KsK.inverse(), Ksf)\n",
    "    u_ob.set_weights(w)\n",
    "\n",
    "\n",
    "    b = np.linspace(-1,1,im_len)#np.array([x[0]])#np.linspace(-1,1,100)\n",
    "    xf= np.linspace(-1,1,im_len)#x#np.linspace(-1,1,100)\n",
    "    BF, XF = np.meshgrid(b,xf)\n",
    "\n",
    "    X_test = u_ob.data_axes([b,xf]).T\n",
    "    #print('X_test.shape',X_test.shape)\n",
    "    X_final = u_ob.data_axes([x,x]).T\n",
    "    pred = u_ob(X_test).T[0].reshape(len(b),len(xf)).detach().numpy()\n",
    "    GT = Fr.reshape(len(x),len(x))\n",
    "    pred[np.where(pred < 0.0)] = 0\n",
    "    recIM = pred.reshape(im_len,im_len)\n",
    "\n",
    "    return recIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14592/1353063009.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Fr = torch.tensor(Fr)\n",
      "/tmp/ipykernel_14592/1111729620.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_14592/1111729620.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1])#.float()\n",
      "/tmp/ipykernel_14592/1111729620.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2])#.float()\n"
     ]
    }
   ],
   "source": [
    "# Next is Sobolev Fitting\n",
    "\n",
    "\n",
    "deg_Quads = [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22, 25, 27]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 23\n",
    "    rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #print(rect.shape)\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #print('diffeo_param',diffeo_param)\n",
    "    sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    #print('sob_param',sob_param)\n",
    "\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    sob_param.set_s(0)\n",
    "    #####\n",
    "    x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    metric_param = sob_param.metric()\n",
    "    W_param = sob_param.get_leja_weights()\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    metric_2d = sob_param.metric(weak=True)\n",
    "    x_l = sob_param.get_xs()\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "    #X_p = X_p.float()\n",
    "\n",
    "    Q_exact = im_len/2 *(x+1)\n",
    "\n",
    "    testRK = getLejaOrderedImage(orig, Q_exact)\n",
    "    testRK = testRK.double()\n",
    "    recIM = getImageFromCoefficients(testRK,X_p )\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(32,32)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    pert_coeff = pert_coeff.double()\n",
    "    #print(pert_coeff.shape)\n",
    "\n",
    "\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1])#.float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    pert_coeff = pert_coeff.double()\n",
    "\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2])#.float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "\n",
    "    pert_coeff = pert_coeff.double()\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(32,32)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.644062397282818,\n",
       " 12.082815865899875,\n",
       " 12.880550310614945,\n",
       " 11.988318944540035,\n",
       " 12.661095283433488,\n",
       " 14.097114095406745,\n",
       " 15.39888883103952,\n",
       " 14.436706554443594,\n",
       " 14.342850171880336,\n",
       " 14.566283823255823,\n",
       " 13.847059887361741,\n",
       " 15.10203415085386,\n",
       " 15.937678661904705,\n",
       " 15.876372978339464,\n",
       " 16.29145103687781,\n",
       " 17.03237245392166]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.629645665665086,\n",
       " 12.171879442471784,\n",
       " 13.02496752678545,\n",
       " 11.863842423425876,\n",
       " 12.737362467569579,\n",
       " 14.112424901981163,\n",
       " 15.472300943509946,\n",
       " 14.533757504527047,\n",
       " 14.491068915927672,\n",
       " 14.765883602594457,\n",
       " 13.933461547977357,\n",
       " 15.193903901607559,\n",
       " 15.940658505874142,\n",
       " 15.776454152405577,\n",
       " 16.237259708048178,\n",
       " 17.079512683204776]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_noise4p3_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3692b3ef59e7728d2be3452101a8b78f0eb4de921f81f985613a05eb18e1c282"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
