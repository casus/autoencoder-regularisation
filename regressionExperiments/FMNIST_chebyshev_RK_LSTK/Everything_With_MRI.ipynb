{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import minterpy as mp\n",
    "from minterpy.extras.regression import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFashionMNIST(batch_size = 10):\n",
    "    fashionmnist_data = torchvision.datasets.FashionMNIST(download=True, root = 'data/fashionmnist', transform = \n",
    "                                                                                 transforms.Compose([transforms.Resize(32),\n",
    "                                                                                 transforms.ToTensor(), \n",
    "                                                                                 transforms.Lambda(lambda x: x.repeat(1, 1, 1))\n",
    "                                                                                 ]))\n",
    "\n",
    "    fashionmnist_data_test = torchvision.datasets.FashionMNIST(download=True, root = 'data/fashionmnist', train=False, transform = \n",
    "                                                                                 transforms.Compose([transforms.Resize(32),\n",
    "                                                                                 transforms.ToTensor(), \n",
    "                                                                                 transforms.Lambda(lambda x: x.repeat(1, 1, 1))\n",
    "                                                                                 ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(fashionmnist_data,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=16)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(fashionmnist_data_test,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=16)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "def getDataset(dataset = \"MNIST\", batch_size = 10):\n",
    "    if(dataset == \"MNIST\"):\n",
    "        train_loader, test_loader = getMNIST(batch_size)\n",
    "        noChannels,dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "    elif(dataset == \"FashionMNIST\"):\n",
    "        train_loader, test_loader = getFashionMNIST(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "    elif(dataset == \"Cifar10\"):\n",
    "        train_loader, test_loader = getCifar10(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "        \"\"\"\n",
    "    elif(dataset == \"cityscapes\"):\n",
    "        train_loader, test_loader = getcityscapes(batch_size)\n",
    "        noChannels, dx, dy = train_loader.dataset.__getitem__(1)[0].shape\n",
    "        \"\"\"\n",
    "    else:\n",
    "        return None, None, None, None, None    \n",
    "        \n",
    "    return train_loader, test_loader, noChannels, dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader, noChannels, dx, dy = getDataset(\"FashionMNIST\", 60000)  # FashionMNIST , MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inum, (batch_x, label) in enumerate(train_loader):\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = batch_x[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the image<class 'nibabel.nifti1.Nifti1Image'>.\n"
     ]
    }
   ],
   "source": [
    "image_path = '/media/chethan/New Volume/Thesis/mri_learning/mri_dwi_dataset/OASIS3/OAS30063/OAS30063_MR_d0160/dwi1/NIFTI/sub-OAS30063_ses-d0160_dwi.nii.gz'\n",
    "\n",
    "image_obj = nib.load(image_path)\n",
    "\n",
    "print(f'Type of the image{type(image_obj)}.')\n",
    "image_data = image_obj.get_fdata()\n",
    "type(image_data)\n",
    "\n",
    "image_data[np.where(image_data < 0)] = 0\n",
    "image_data = (image_data - image_data.min()) / ((image_data.max() - image_data.min()))\n",
    "#print(image_data.mean())\n",
    "#image_data[np.where(image_data < image_data.mean()+image_data.std())] = 0\n",
    "#image_data = image_data / image_data.max()\n",
    "\n",
    "cleaned_image = image_data[:,:,40,0]\n",
    "cleaned_image.shape\n",
    "\n",
    "orig = cleaned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "import scipy.integrate\n",
    "#sys.path.insert(1, '/home/suarez08/PhD_PINNs/PIPS_framework')\n",
    "from jmp_solver.sobolev import Sobolev\n",
    "from jmp_solver.sobolev import Sobolev\n",
    "from jmp_solver.solver import Solver\n",
    "from jmp_solver.utils import matmul\n",
    "import jmp_solver.surrogates\n",
    "import time\n",
    "#sys.path.insert(1, '/home/suarez08/minterpy/src')\n",
    "import minterpy as mp\n",
    "from jmp_solver.diffeomorphisms import hyper_rect\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#style.use('dark_background')\n",
    "matplotlib.rcdefaults() \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22468/3591987762.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_22468/3591987762.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_22468/3591987762.py:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "deg_Quads = [40, 50, 60, 65, 70, 80]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    diffeo_param = hyper_rect(*rect)\n",
    "    sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    sob_param.set_s(0)\n",
    "    #####\n",
    "    x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    metric_param = sob_param.metric()\n",
    "    W_param = sob_param.get_leja_weights()\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    metric_2d = sob_param.metric(weak=True)\n",
    "    x_l = sob_param.get_xs()\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,96)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "        #print('listedImage.shape',listedImage.shape)\n",
    "        Fr = torch.tensor(listedImage).reshape(96*96)\n",
    "\n",
    "        def grad_x(t,theta):\n",
    "            theta_t = torch.tensor(theta)\n",
    "            return -2*torch.matmul(X_p.T,(torch.matmul(X_p,theta_t)-Fr)).detach().numpy()\n",
    "\n",
    "        def give_theta_t():\n",
    "            start = time.time()\n",
    "            u_ob.set_weights_val(0.0)\n",
    "            theta_0 =  list(u_ob.parameters())[0][0]\n",
    "            dt = 0.01\n",
    "            theta_t = theta_0\n",
    "            for k in range(20):\n",
    "                theta_int =  scipy.integrate.RK45(grad_x, 0.1, theta_t.detach().numpy(), 100)\n",
    "                theta_int.step()\n",
    "                theta_t = torch.tensor(theta_int.y)\n",
    "            return theta_t\n",
    "\n",
    "        act_theta = give_theta_t()\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(96,96)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_MRI_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_MRI_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_MRI_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/RK_MRI_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.54758601396036,\n",
       " 23.979189870014515,\n",
       " 25.767243442431337,\n",
       " 26.32213515750834,\n",
       " 27.545704028638003,\n",
       " 29.305213575968093]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for Analytical\n",
    "\n",
    "\n",
    "\n",
    "#orig = batch_x[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22468/4062282975.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_22468/4062282975.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_22468/4062282975.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "deg_Quads = [40, 50, 60, 65, 70, 80]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    #rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    #sob_param.set_s(0)\n",
    "    #####\n",
    "    #x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    #metric_param = sob_param.metric()\n",
    "    #W_param = sob_param.get_leja_weights()\n",
    "    #u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    #metric_2d = sob_param.metric(weak=True)\n",
    "    #x_l = sob_param.get_xs()\n",
    "    #X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,96)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "        Fr = torch.tensor(listedImage).reshape(96*96).double()\n",
    "        KsK = matmul(X_p.T, X_p)\n",
    "        Ksf = matmul(X_p.T, Fr)\n",
    "        w = matmul(KsK.inverse(), Ksf)\n",
    "\n",
    "        act_theta = w\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(96,96)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_MRI_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_MRI_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_MRI_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/Analytic_MRI_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.256353784651166,\n",
       " 15.16826797604606,\n",
       " 15.17076498995149,\n",
       " 15.16407096354799,\n",
       " 15.157777386252743,\n",
       " 15.179097292651026]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_noise4p3_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.689460848850164,\n",
       " 24.65499565315675,\n",
       " 12.492747567899567,\n",
       " 13.558073263348136,\n",
       " 13.269721052914951,\n",
       " 14.537121518921875]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22468/3788239765.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  get = np.linalg.lstsq(np.array(X_p), listedImage.reshape(96*96), rcond='warn')\n",
      "/tmp/ipykernel_22468/3788239765.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_22468/3788239765.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
      "/tmp/ipykernel_22468/3788239765.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2]).float()\n"
     ]
    }
   ],
   "source": [
    "# Next is LSTQS\n",
    "\n",
    "deg_Quads = [40, 50, 60, 65, 70, 80]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 7\n",
    "    #rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    #sob_param.set_s(0)\n",
    "    #####\n",
    "    #x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    #metric_param = sob_param.metric()\n",
    "    #W_param = sob_param.get_leja_weights()\n",
    "    #u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    #metric_2d = sob_param.metric(weak=True)\n",
    "    #x_l = sob_param.get_xs()\n",
    "    #X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    x = np.linspace(-1,1,96)\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "\n",
    "    def get_all_thetas(listedImage):\n",
    "\n",
    "        get = np.linalg.lstsq(np.array(X_p), listedImage.reshape(96*96), rcond='warn')\n",
    "        act_theta = torch.tensor(get[0])\n",
    "        return act_theta\n",
    "\n",
    "    testRK = get_all_thetas(orig)\n",
    "    testRK = testRK.float()\n",
    "    recIM = torch.matmul(X_p.float(), testRK.T).T\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(96,96)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2]).float()\n",
    "    recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_MRI_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_MRI_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_MRI_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/LSTQS_MRI_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_len = orig.shape[0]\n",
    "im_len\n",
    "def getLejaOrderedImage(im2d, Q_exact):\n",
    "    Q_exact_sorted = (Q_exact)\n",
    "    leg_pts_image_sorted = torch.tensor([])\n",
    "    for i in Q_exact_sorted:\n",
    "        for j in Q_exact_sorted:\n",
    "            i_int = i.astype(int)\n",
    "            j_int = j.astype(int)\n",
    "            if(i_int == 0 or i_int == (im_len-1) or j_int == 0 or j_int == (im_len-1) ):\n",
    "                req_value = im2d[i_int][j_int]\n",
    "            else:\n",
    "                x_co_1 = i_int\n",
    "                x_co_2 = i_int+1\n",
    "                y_co_1 =j_int\n",
    "                y_co_2 = j_int+1\n",
    "\n",
    "                Q_ev_11 = im2d[x_co_1][y_co_1]\n",
    "                Q_ev_12 = im2d[x_co_1][y_co_2]\n",
    "                Q_ev_21 = im2d[x_co_2][y_co_1]\n",
    "                Q_ev_22 = im2d[x_co_2][y_co_2]\n",
    "\n",
    "                x_co = i\n",
    "                y_co = j\n",
    "\n",
    "                term_1 = ( ( ( (x_co_2 - x_co) * (y_co_2 - y_co) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_11)\n",
    "                term_2 = (( ( (x_co - x_co_1) * (y_co_2 - y_co) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_21)\n",
    "                term_3 = ( ( ( (x_co_2 - x_co) * (y_co - y_co_1) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_12)\n",
    "                term_4 = ( ( ( (x_co - x_co_1) * (y_co - y_co_1) ) / ( (x_co_2 - x_co_1) * (y_co_2 - y_co_1) ) ) * Q_ev_22)\n",
    "\n",
    "                req_value = term_1 + term_2 + term_3 + term_4                \n",
    "            Fr1 = torch.tensor([req_value])\n",
    "            leg_pts_image_sorted = torch.cat((leg_pts_image_sorted, Fr1)) \n",
    "    return leg_pts_image_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the analytic gradient flow, the trained model is u_ob\n",
    "\n",
    "def getImageFromCoefficients(imageBilinearEncoded,X_p ):\n",
    "    Fr = imageBilinearEncoded\n",
    "    Fr = torch.tensor(Fr)\n",
    "    start = time.time()\n",
    "    K = torch.eye(len(X_p))\n",
    "    KsK = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),X_p)))\n",
    "    Ksf = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),Fr)))\n",
    "    w = matmul(KsK.inverse(), Ksf)\n",
    "    u_ob.set_weights(w)\n",
    "    end = time.time()\n",
    "    #print('time consumption: %.2fs' % (end-start))\n",
    "\n",
    "    Ksf = matmul(X_p.T, metric_2d(matmul(torch.diag(W_param),Fr)))\n",
    "    w = matmul(KsK.inverse(), Ksf)\n",
    "    u_ob.set_weights(w)\n",
    "\n",
    "\n",
    "    b = np.linspace(-1,1,im_len)#np.array([x[0]])#np.linspace(-1,1,100)\n",
    "    xf= np.linspace(-1,1,im_len)#x#np.linspace(-1,1,100)\n",
    "    BF, XF = np.meshgrid(b,xf)\n",
    "\n",
    "    X_test = u_ob.data_axes([b,xf]).T\n",
    "    #print('X_test.shape',X_test.shape)\n",
    "    X_final = u_ob.data_axes([x,x]).T\n",
    "    pred = u_ob(X_test).T[0].reshape(len(b),len(xf)).detach().numpy()\n",
    "    GT = Fr.reshape(len(x),len(x))\n",
    "    pred[np.where(pred < 0.0)] = 0\n",
    "    recIM = pred.reshape(im_len,im_len)\n",
    "\n",
    "    return recIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22468/1353063009.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Fr = torch.tensor(Fr)\n",
      "/tmp/ipykernel_22468/3650242546.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
      "/tmp/ipykernel_22468/3650242546.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[1])#.float()\n",
      "/tmp/ipykernel_22468/3650242546.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pert_coeff = torch.tensor(orig_perturb[2])#.float()\n"
     ]
    }
   ],
   "source": [
    "# Next is Sobolev Fitting\n",
    "\n",
    "\n",
    "deg_Quads = [40, 50, 60, 65, 70, 80]\n",
    "\n",
    "all_direct_recons_psnr = []\n",
    "all_noise1_recons_psnr = []\n",
    "all_noise2_recons_psnr = []\n",
    "all_noise4p3_recons_psnr = []\n",
    "\n",
    "for deg_quad in deg_Quads:\n",
    "    #deg_quad = 23\n",
    "    rect = rect = np.array([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "    #print(rect.shape)\n",
    "    #diffeo_param = hyper_rect(*rect)\n",
    "    #print('diffeo_param',diffeo_param)\n",
    "    sob_param = Sobolev(deg=deg_quad, dim=2)\n",
    "    #print('sob_param',sob_param)\n",
    "\n",
    "    ##### Sobolev norm for the inteprolation\n",
    "    sob_param.set_s(0)\n",
    "    #####\n",
    "    x_plt, _, _, x, _, _ = sob_param.get_quad()\n",
    "    metric_param = sob_param.metric()\n",
    "    W_param = sob_param.get_leja_weights()\n",
    "    u_ob = jmp_solver.surrogates.Polynomial(n=deg_quad,p=np.inf, dim=2)\n",
    "    metric_2d = sob_param.metric(weak=True)\n",
    "    x_l = sob_param.get_xs()\n",
    "    X_p = u_ob.data_axes([x,x]).T\n",
    "    #X_p = X_p.float()\n",
    "\n",
    "    Q_exact = im_len/2 *(x+1)\n",
    "\n",
    "    testRK = getLejaOrderedImage(orig, Q_exact)\n",
    "    testRK = testRK.double()\n",
    "    recIM = getImageFromCoefficients(testRK,X_p )\n",
    "    recIM[np.where(recIM < 0.0)] = 0\n",
    "    recIM = recIM.reshape(96,96)\n",
    "\n",
    "    # PSNR of direct backward reconstruction of coefficients without perturbation \n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_norm = Normalize()(recIM)\n",
    "    direct_recon_psnr = psnr(orig_normal, recIM_norm, data_range=1.)\n",
    "    \n",
    "    all_direct_recons_psnr.append(direct_recon_psnr)\n",
    "\n",
    "    # MSE of direct reconstruction\n",
    "\n",
    "    direct_recon_mse = np.mean(((orig_normal - np.array(recIM_norm))**2)*0.5)\n",
    "\n",
    "    prozs = [0.01, 0.02, 0.0423, 0.7] \n",
    "\n",
    "\n",
    "    rand_perturb = []\n",
    "\n",
    "    testRK_pert = np.array(testRK)\n",
    "    testRK_pert = testRK_pert.reshape(1,testRK_pert.shape[0])\n",
    "    for proz in prozs:\n",
    "        \n",
    "        rand_perturb.append(np.random.rand(1,testRK_pert.shape[1])*(np.max(testRK_pert)-np.min(testRK_pert))*proz)\n",
    "\n",
    "    orig_perturb = []\n",
    "    for rand_transform in rand_perturb:\n",
    "        orig_perturb.append(torch.from_numpy(np.add(testRK_pert,rand_transform)).reshape(rand_transform.shape))#.to(device))\n",
    "        \n",
    "    pert_coeff = torch.tensor(orig_perturb[0]).float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    pert_coeff = pert_coeff.double()\n",
    "    #print(pert_coeff.shape)\n",
    "\n",
    "\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    \n",
    "\n",
    "\n",
    "    orig_normal = Normalize()(orig)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise1_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    \n",
    "    all_noise1_recons_psnr.append(noise1_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[1])#.float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "    pert_coeff = pert_coeff.double()\n",
    "\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "\n",
    "    noise2_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise2_recons_psnr.append(noise2_psnr)\n",
    "\n",
    "    pert_coeff = torch.tensor(orig_perturb[2])#.float()\n",
    "    #recIM_pert10 = torch.matmul(X_p.float(), pert_coeff.T).T\n",
    "\n",
    "    pert_coeff = pert_coeff.double()\n",
    "    recIM_pert10 = getImageFromCoefficients(pert_coeff[0],X_p )\n",
    "\n",
    "    recIM_pert10[np.where(recIM_pert10 < 0.0)] = 0\n",
    "    recIM_pert10 = recIM_pert10.reshape(96,96)\n",
    "\n",
    "    recIM_pert10_norm = Normalize()(recIM_pert10)\n",
    "    noise4p3_psnr = psnr(orig_normal, recIM_pert10_norm, data_range=1.)\n",
    "    all_noise4p3_recons_psnr.append(noise4p3_psnr)\n",
    "\n",
    "torch.save(all_direct_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_MRI_direct_recon_psnr.pt')\n",
    "torch.save(all_noise1_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_MRI_all_noise1_recons_psnr.pt')\n",
    "torch.save(all_noise2_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_MRI_all_noise2_recons_psnr.pt')\n",
    "torch.save(all_noise4p3_recons_psnr, '/media/chethan/New Volume/Thesis/regressionExperiments/sobolev_MRI_all_noise4p3_recons_psnr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.346862548625474,\n",
       " 20.875955749899923,\n",
       " 22.109724921521966,\n",
       " 22.378746573547485,\n",
       " 22.235325639670037,\n",
       " 23.24782391902946]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_direct_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.952330844273423,\n",
       " 20.47516533159505,\n",
       " 21.81634886014887,\n",
       " 21.95561385535821,\n",
       " 21.573355662292812,\n",
       " 22.65224303710223]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_noise4p3_recons_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3692b3ef59e7728d2be3452101a8b78f0eb4de921f81f985613a05eb18e1c282"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
