
before normalize 123
after normalize 123
initial torch.Size([123, 96, 96, 60])
after permute torch.Size([123, 60, 96, 96])
after 123 torch.Size([123, 25, 96, 96])
after reshape torch.Size([3075, 96, 96])
after unsqueeze torch.Size([3075, 1, 96, 96])
before normalize 490
after normalize 490
initial torch.Size([490, 96, 96, 60])
after permute torch.Size([490, 60, 96, 96])
after 123 torch.Size([490, 25, 96, 96])
after reshape torch.Size([12250, 96, 96])
after unsqueeze torch.Size([12250, 1, 96, 96])
train_data.shape torch.Size([3075, 1, 96, 96])
  0%|                                                                                                           | 0/50 [00:00<?, ?it/s]/home/ramana44/autoencoder-regularisation-/training_call_Hybrid_AEs_MRI/train_hybrid_AEREG_MRI.py:210: UserWarning: torch.matrix_rank is deprecated in favor of torch.linalg.matrix_rankand will be removed in a future PyTorch release. The parameter 'symmetric' was renamed in torch.linalg.matrix_rank to 'hermitian'. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180549130/work/aten/src/ATen/native/LinearAlgebra.cpp:464.)
  rank_Jacm = float(torch.matrix_rank(Jac_m, tol=1e-1).cpu().detach().numpy())
[0] rAE rank = 10, cond = 1.9056e+00
[0] rAE rank = 10, cond = 2.2192e+00
[0] rAE rank = 10, cond = 2.0449e+00
[0] rAE rank = 10, cond = 2.1794e+00
[0] rAE rank = 10, cond = 2.8999e+00
[0] rAE rank = 10, cond = 2.7827e+00
[0] rAE loss = 4.9046e-03, rAE reconstruction loss = 3.3302e-03
  2%|█▉                                                                                                 | 1/50 [00:08<07:10,  8.78s/it]
[1] rAE rank = 10, cond = 2.2666e+00
[1] rAE rank = 10, cond = 1.7771e+00
[1] rAE rank = 10, cond = 1.7354e+00
[1] rAE rank = 10, cond = 1.7373e+00
[1] rAE rank = 10, cond = 1.6690e+00

  4%|███▉                                                                                               | 2/50 [00:16<06:43,  8.41s/it]
[1] rAE loss = 3.1651e-03, rAE reconstruction loss = 2.4126e-03
[2] rAE rank = 10, cond = 1.5849e+00
[2] rAE rank = 10, cond = 1.8109e+00
[2] rAE rank = 10, cond = 1.7896e+00
[2] rAE rank = 10, cond = 1.5705e+00

  6%|█████▉                                                                                             | 3/50 [00:25<06:29,  8.28s/it]
[2] rAE rank = 10, cond = 1.8044e+00
[2] rAE loss = 2.9181e-03, rAE reconstruction loss = 2.0755e-03
[3] rAE rank = 10, cond = 1.6058e+00
[3] rAE rank = 10, cond = 1.6382e+00
[3] rAE rank = 10, cond = 1.6325e+00
[3] rAE rank = 10, cond = 1.6681e+00

  8%|███████▉                                                                                           | 4/50 [00:33<06:17,  8.21s/it]
[3] rAE rank = 10, cond = 1.5941e+00
[3] rAE loss = 2.7915e-03, rAE reconstruction loss = 1.9589e-03
[4] rAE rank = 10, cond = 1.5889e+00
[4] rAE rank = 10, cond = 1.5298e+00
[4] rAE rank = 10, cond = 1.5457e+00
[4] rAE rank = 10, cond = 1.5878e+00

 10%|█████████▉                                                                                         | 5/50 [00:41<06:07,  8.16s/it]
[4] rAE rank = 10, cond = 1.4999e+00
[4] rAE loss = 2.8061e-03, rAE reconstruction loss = 1.9146e-03
[5] rAE rank = 10, cond = 1.5199e+00
[5] rAE rank = 10, cond = 1.6265e+00
[5] rAE rank = 10, cond = 1.6745e+00
[5] rAE rank = 10, cond = 1.6446e+00

 12%|███████████▉                                                                                       | 6/50 [00:49<05:57,  8.14s/it]
[5] rAE rank = 10, cond = 1.6252e+00
[5] rAE loss = 2.6818e-03, rAE reconstruction loss = 1.8861e-03
[6] rAE rank = 10, cond = 1.6009e+00
[6] rAE rank = 10, cond = 1.6125e+00
[6] rAE rank = 10, cond = 1.7301e+00
[6] rAE rank = 10, cond = 1.6037e+00

 14%|█████████████▊                                                                                     | 7/50 [00:57<05:51,  8.16s/it]
[6] rAE rank = 10, cond = 1.6626e+00
[6] rAE loss = 2.7653e-03, rAE reconstruction loss = 1.8779e-03
[7] rAE rank = 10, cond = 1.7450e+00
[7] rAE rank = 10, cond = 1.6558e+00
[7] rAE rank = 10, cond = 1.5420e+00
[7] rAE rank = 10, cond = 1.6481e+00

 16%|███████████████▊                                                                                   | 8/50 [01:05<05:41,  8.14s/it]
[7] rAE rank = 10, cond = 1.5792e+00
[7] rAE loss = 2.7592e-03, rAE reconstruction loss = 1.8711e-03
[8] rAE rank = 10, cond = 1.6880e+00
[8] rAE rank = 10, cond = 1.6881e+00
[8] rAE rank = 10, cond = 1.6867e+00
[8] rAE rank = 10, cond = 1.6302e+00

 18%|█████████████████▊                                                                                 | 9/50 [01:13<05:35,  8.17s/it]
[8] rAE rank = 10, cond = 1.5936e+00
[8] rAE loss = 2.6588e-03, rAE reconstruction loss = 1.8563e-03
[9] rAE rank = 10, cond = 1.5320e+00
[9] rAE rank = 10, cond = 1.6114e+00
[9] rAE rank = 10, cond = 1.7210e+00
[9] rAE rank = 10, cond = 1.5259e+00

 20%|███████████████████▌                                                                              | 10/50 [01:21<05:25,  8.15s/it]
[9] rAE rank = 10, cond = 1.6072e+00
[9] rAE loss = 2.8109e-03, rAE reconstruction loss = 1.8458e-03
[10] rAE rank = 10, cond = 1.6230e+00
[10] rAE rank = 10, cond = 1.6054e+00
[10] rAE rank = 10, cond = 1.7782e+00
[10] rAE rank = 10, cond = 1.7604e+00

 22%|█████████████████████▌                                                                            | 11/50 [01:30<05:16,  8.12s/it]
[10] rAE rank = 10, cond = 1.7494e+00
 22%|█████████████████████▌                                                                            | 11/50 [01:32<05:28,  8.43s/it]
Traceback (most recent call last):
  File "/home/ramana44/autoencoder-regularisation-/training_call_Hybrid_AEs_MRI/Hybrid_AEREG_MRI.py", line 113, in <module>
    model, model_reg, loss_arr_reg, loss_arr_reco, loss_arr_base, loss_arr_val_reco, loss_arr_val_base = train(image_batches_trn, image_batches_test, coeffs_saved_trn, coeffs_saved_test, no_epochs=50, reco_loss="mse", latent_dim=latent_dim,
  File "/home/ramana44/autoencoder-regularisation-/training_call_Hybrid_AEs_MRI/train_hybrid_AEREG_MRI.py", line 172, in train
    loss_C1, Jac = computeC1Loss_upd(nodes_subsample, model_reg, device, guidanceTerm = use_guidance) # guidance term
  File "/home/ramana44/autoencoder-regularisation-/./regularisers_without_vegas_fmnist.py", line 182, in computeC1Loss_upd
    Jac = torch.autograd.functional.jacobian(f, node_points.to(device), create_graph = True).squeeze() # compute Jacobian
  File "/home/ramana44/.conda/envs/myenv/lib/python3.9/site-packages/torch/autograd/functional.py", line 579, in jacobian
    vj = _autograd_grad((out.reshape(-1)[j],), inputs,
  File "/home/ramana44/.conda/envs/myenv/lib/python3.9/site-packages/torch/autograd/functional.py", line 147, in _autograd_grad
    return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,
  File "/home/ramana44/.conda/envs/myenv/lib/python3.9/site-packages/torch/autograd/__init__.py", line 234, in grad
    return Variable._execution_engine.run_backward(
KeyboardInterrupt
[11] rAE rank = 10, cond = 1.7561e+00
[11] rAE rank = 10, cond = 1.5098e+00